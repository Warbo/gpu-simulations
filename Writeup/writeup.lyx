#LyX 1.6.5 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{program}
\usepackage{listings}
\end_preamble
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Physics Simulations on Graphics Cards
\end_layout

\begin_layout Abstract
A collection of computer simulations is presented which implements a Smoothed-Pa
rticle Hydrodynamics model through the use of CUDA.
 CUDA is a library developed by Nvidia to allow arbitrary computation to
 be performed by the company's Graphics Processing Units: a cheap, massively
 parallel hardware architecture.
 The SPH model was chosen as an example of a non-trivial application, and
 an emphasis was placed on producing reusable, generic algorithms and code.
 Whilst the difficulties of parallel programming were taken into account
 from the start, throughout the implementation lessons were learned about
 the abilities and limitations of CUDA and how best to utilise this new
 technology.
 After an extensive introduction to the difficulties of parallel programming,
 these implementation details are presented in the hope that they prove
 useful to future coding projects.
 Finally the results of the effort are discussed which, averaged over the
 measurements taken, show the CUDA code to be 23 times faster than the CPU
 at the naive brute force model and 4 times faster than the CPU at the optimised
 grid model.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Physics, indeed the whole of science, is the attempt to describe the world
 with Mathematics.
 Computers have become an invaluable tool in this endeavour.
 Not only through the secondary, Model Theoretic, semantic interpretation
 of the side-effects caused by their programs: results to calculations,
 instant communication between collaborators around the world, mass storage
 and retrieval of knowledge and observations from experiments impossible
 to percieve manually.
 At a much more fundamental level, the principle of operation of a computing
 device, the syntactic manipulation of symbols, is isomorphic to the application
 of Proof Theory to a deductive system
\begin_inset CommandInset citation
LatexCommand cite
key "Curry1934,Curry1958,Howard1969"

\end_inset

.
\end_layout

\begin_layout Standard
Since the defining characteristic of Mathematics is the discovery and proof
 of theorems, by their very existence computers provide the Scientist with
 a physical manifestation of Mathematics, in fact the most powerful known
 to exist
\begin_inset CommandInset citation
LatexCommand cite
key "Church1936,Turing1936,Turing1938"

\end_inset

, and thus the most useful tool there is in the endeavour to formalise the
 Universe.
 This is especially elegant for the Physicist, who's attempts to describe
 reality with Mathematical laws are enabled by the exploitation of those
 laws in their own derivation
\begin_inset CommandInset citation
LatexCommand cite
key "Goedel1931"

\end_inset

.
\end_layout

\begin_layout Standard
With the mechanisation of proof, the role of the Scientist has shifted towards
 that of the programmer: the discoverer of algorithms.
 The space being explored for this discovery is that of provably true theorems
 and the goal is interestingness and surprise
\begin_inset CommandInset citation
LatexCommand cite
key "Schmidhuber2009"

\end_inset

.
 No more information is contained in a theorem than already exists in its
 axioms, but only through term-rewriting can we see this information in
 new ways and thus gain insights into the models with which we describe
 reality.
\end_layout

\begin_layout Subsection
Physics with Computers
\end_layout

\begin_layout Standard
Computers are only as useful as the theorems they prove, and it is the computer'
s 
\emph on
program
\emph default
 (a combination of software and hardware) which defines the operations to
 take.
 The job of the programmer is to define programs such that their algebra
 encapsulates the model under investigation.
 There are many ways to approach this task, arbitrarily categorised as 
\emph on
high-level
\emph default
 (bearing little relation to the machine) such as 
\begin_inset Quotes eld
\end_inset

interactive theorem provers
\begin_inset Quotes erd
\end_inset

, virtual machines and pure functional languages; and 
\emph on
low-level
\emph default
, which describes direct use of a machine's instructions or components,
 or simple abstractions based on them such as macros.
 Of course all are equivalent in computational power
\begin_inset CommandInset citation
LatexCommand cite
key "Turing1936,Turing1938"

\end_inset

, but are necessarily distinct in order to minimise the transformation from
 our mental model to the programming paradigm.
 In this project the 
\emph on
simulation
\emph default
 approach is taken, which is a
\emph on
 
\emph default
low-level implementation that uses machine components to numerically approximate
 the objects described by the model.
\end_layout

\begin_layout Standard
The main advantage to simulations is the lack of abstractions such as sets,
 ranges, derivatives, etc.
 which are often used to model the behaviour of large systems.
 In a simulation, a (usually) simple correspondance is made between the
 physical system of the model and the physical system of the machine.
 This makes programming simulations a relatively straightforward affair,
 and the results contain much more information than the existential and
 aggregate output obtained from more abstract models.
 The proof is also stronger as it depends on the validity of fewer assumptions.
 However, this inevitably leads to the biggest problem of simulations: their
 consumption of resources.
\end_layout

\begin_layout Standard
Less intensive symbol manipulation, such as statistical mechanics, is simple
 enough to perform manually, whereas simulation had to wait for the advent
 of fast mechanical computers before it could tackle systems of similar
 complexity.
 Despite the inefficiency of the technique, being able to act relatively
 safely at a low level keeps overhead low, such that few resources are wasted,
 and from a more practical point of view being able to perform this mapping
 manually at a low level gives a performance advantage considering that
 language development and pattern matching are still in their infancy as
 Mathematical disciplines.
\end_layout

\begin_layout Standard
Another disadvantage to simulations is the error introduced by numerically
 approximating Real values of a model with the Rational values of the computer,
 requiring extra care to be taken to ensure that the rules are being applied
 appropriately.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For example this project makes extensive use of 
\emph on
assertions
\emph default
: statements placed strategically throughout the code which explicitly state
 the assumptions being made and abort the execution if they are not valid.
 Due to the limited precision of the input, perfectly valid actions were
 being flagged as inappropriate since the decision to take the action was
 rounding a different way than the sanity check afterwards.
 By giving the assertions a safe margin of precision the problem of false
 positives was eliminated.
 
\end_layout

\end_inset

 The magnitude of these errors is usually insignificant, however they can
 depend on the resolution of the simulation which, for each spacetime dimension,
 linearly affects the amount of computation to perform.
 High resolution is important for Physics simulations, as many Physical
 laws are defined as differential equations, and thus simulation becomes
 discrete summation as an approximation to the continuous integration of
 the system under these laws.
 The smaller the summation steps, the closer the approximation becomes.
\end_layout

\begin_layout Standard
The chosen resolution also depends on the physical properties of the intended
 machine, since machine instructions can only manipulate machine numbers
 and thus anything outside that range requires algorithmic abstractions.
 For example, on a 64-bit machine it is not possible to exactly represent,
 as a machine number, a binary Natural 
\begin_inset Formula $x\geq10^{1000000}+1$
\end_inset

 (decimal 
\begin_inset Formula $2^{64}+1$
\end_inset

) 
\begin_inset CommandInset citation
LatexCommand cite
key "C99"

\end_inset

, and similarly machines following floating point standards
\begin_inset CommandInset citation
LatexCommand cite
key "IEEE754"

\end_inset

 cannot store, as a machine number, a binary Rational such as 
\begin_inset Formula $10^{10000101}+\frac{1}{10}$
\end_inset

 (decimal 
\begin_inset Formula $2^{133}+\frac{1}{2}$
\end_inset

).
 To do so requires a 
\emph on
bignum
\emph default
 (arbitrary-precision arithmetic) library, which stores Integers as a linear
 datastructure of machine numbers, and Rationals as two (a numerator and
 a denominator).
 This severely impacts performance, as the computational complexity of every
 arithmetic operation changes from 
\begin_inset Formula $O\left(1\right)$
\end_inset

 (usually very fast due to 
\emph on
pipelining
\emph default
 in the CPU) to 
\begin_inset Formula $O\left(N_{bits}\right)$
\end_inset

 for addition and subtraction, whilst efficient multiplication algorithms
 are still a research topic (for example the 
\begin_inset Formula $O(N_{bits}\log N_{bits}2^{O(\log^{*}N_{bits})})$
\end_inset

 algorithm from 
\begin_inset CommandInset citation
LatexCommand cite
key "AnindyaDe2008"

\end_inset

).
\end_layout

\begin_layout Standard
Given these constraints, Physics simulations are amongst the most computationall
y intensive programs with practical use (it is common for worthwhile programs
 to be limited by I/O rather than available cycles, and it is of course
 trivial to make intensive programs which derive no meaningful results).
 This project aims to research the computational potential of graphics rendering
 hardware for this expensive task, rather than more traditional (and costly)
 alternatives such as supercomputers and clusters.
\end_layout

\begin_layout Subsection
GPU Overview
\end_layout

\begin_layout Standard
A typical commodity computer (ie.
 not intended for embedded or server use) will contain a graphics card,
 either as a plug-in circuit board or integrated into the main motherboard.
 The reason for this is historical, since graphical applications like games
 can always make full use of a computer's resources no matter how extensive
 they are, eg.
 by increasing the resolution or frame-rate of the display, and are thus
 always demanding more powerful hardware.
 To keep down the cost of satiating this demand, it was sensible to offload
 graphics tasks to a co-processor which could be upgraded without having
 to buy a whole new computer.
 These co-processors are called GPUs (Graphics Processing Units) and they
 are housed along with their life-support components on the graphics card.
\end_layout

\begin_layout Standard
Real-time 3D rendering was certainly the main driving force for graphics
 card development, for example most modern GPUs no longer contain explicit
 circuitry for 2D rendering, instead using the space to expand the 3D engine
 and emulating any 2D processing calls.
 The most striking difference between 3D graphics and other common computing
 tasks is that it is an 
\emph on
embarrassingly parallel
\emph default
 problem.
 In other words, it is trivial to get a near 100% increase in performance
 simply by doubling the number of computers that are working on the task
 at once.
\end_layout

\begin_layout Standard
In general such speedups are hard to achieve, since allowing many machines
 to access mutable variables at once requires 
\emph on
locks
\emph default
 to prevent conflicting changes, which themselves bring notoriously difficult
 to spot problems like 
\emph on
deadlock
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Deadlock describes a situation where two machines require two locks before
 accessing memory; one machine holds one lock, the other machine holds the
 other lock and neither is capable of proceeding.
\end_layout

\end_inset

.
 A trivial method, such as an optimisation pass in a compiler, for effectively
 utilising resources in parallel is a much sought-after goal in many research
 groups.
 The fact that 3D graphics scales so easily makes the difficulties of parallel
 programming seem embarassing in comparison.
\end_layout

\begin_layout Standard
The reason 3D is so inherently parallel is that there is very little dependence
 between the calculations being performed.
 This means, for example, that the screen can be split into sections, each
 sent to a different processor for rendering, then the results collected
 and displayed together.
 Any additional resources can be utilised by splitting the screen into more
 sections.
 This put GPU manufacturers in a much better position than their rival CPU
 manufacturers: instead of having to squeeze more performance out of already
 extensively optimised processors, by focusing on an embarassingly parallel
 task they could get more performance by just adding more of the existing
 processors, creating so-called 
\emph on
multiprocessors
\emph default
.
 Modern GPUs contain a number of multiprocessors, each with several 
\emph on
cores
\emph default
 (processing units), typically 8 per multiprocessor.
 In comparison, mainstream CPUs have only recently become multi-core, and
 quad-core machines are still considered high-end computers despite having
 half the processing cores of a single graphics multiprocessor, of which
 there are several in a cheap GPU.
\end_layout

\begin_layout Standard
The processing capabilities of GPUs have been considered for scientific
 computing for several years 
\begin_inset CommandInset citation
LatexCommand cite
key "ESLarsen2001"

\end_inset

 but until recently calculations would have to be translated into an analogous
 graphical task, sent to the GPU for processing, the results transferred
 back then translated into the original context.
 The overhead of conversion and transfering back and forth between the graphics
 card and the motherboard made this approach too inefficient for practical
 use, and the numerical precision of GPUs was insufficient to make large
 calculations worthwhile
\begin_inset CommandInset citation
LatexCommand cite
key "KFatahalian2004"

\end_inset

.
 Recently these limitations have been overcome by the emergence of General-Purpo
se Graphics Processing Units (
\emph on
GPGPUs
\emph default
), capable of running arbitrary code rather than just graphics tasks.
 Complementary programming interfaces, like Nvidia's CUDA and the less vendor-sp
ecific OpenCL, have become available for accessing the cards from mainstream
 programming languages like C, and with this integration the device specificatio
ns have been brought up to meet the precision standards required by these
 language's compilers.
 This has made them an attractive target on which researchers can offload
 their intensive computations, and this project is no different.
\end_layout

\begin_layout Section
Parallel Programming
\end_layout

\begin_layout Standard
Parallel programming has existed for decades, but outside the realms of
 research and supercomputers has not been pervasive.
 The limited use of multiple 
\emph on
threads
\emph default
 of execution has become well established in areas such as interactive (includin
g graphical) programs and networked software, however this is not 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 parallel programming and is mainly used for stylistic reasons rather than
 raw performance.
 Rather than combining all of the program logic into a 
\begin_inset Quotes eld
\end_inset

main loop
\begin_inset Quotes erd
\end_inset

, different subsystems are segregated to their own functions to keep down
 code complexity.
 To prevent 
\emph on
blocking
\emph default
 (waiting for a function to finish) these are then further segregated to
 their own threads, so that calls to these subsystems then become 
\emph on
asynchronous
\emph default
 (non-blocking, the next instruction is carried out without waiting for
 the call to finish).
\end_layout

\begin_layout Standard
The reason for this not being 
\begin_inset Quotes eld
\end_inset

truly
\begin_inset Quotes erd
\end_inset

 parallel is that the main targets for such software are microcomputers,
 which until recently only had one processing core.
 Thus only one thread runs at a time, rather than all of them running 
\emph on
concurrently
\emph default
, and the instructions are interleaved by 
\emph on
context switching
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
This is managed by the operating system kernel, which stops and starts threads
 one at a time to simulate concurrent execution.
 To prevent threads from breaking each other, the execution environment
 (or context) for each thread is stored alongside it.
 Switching between threads thus requires switching the execution context,
 which may need to fetch values from RAM and is thus costly.
 In modern 
\emph on
preemptive multitasking
\emph default
 systems, context switching is managed by the kernel and its scheduler,
 based on thread priorities.
 The threads themselves have no control over their execution.
\end_layout

\end_inset

.
 There is therefore no increase in the theoretical maximum performance between
 multiple threads and one main loop on one core
\begin_inset CommandInset citation
LatexCommand cite
key "Amdahl1967"

\end_inset

, it is merely simpler and more scalable to implement multiple blocking
 services via threads.
 In fact the overhead of context switching may even incur a performance
 penalty in edge cases.
\end_layout

\begin_layout Standard
The major obstacle to parallel programming, especially when executed concurrentl
y, is that very few assumptions can be made about program state: the interleavin
g and relative speeds of threads (or equivalent) are completely nondeterministic
, so definitions and values may be changed by another thread at any point,
 and the granularity of this interleaving can be incredibly fine.
 A classic example to demonstrate this can be seen in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:A-subtley-flawed"

\end_inset

, which implements a hypothetical banking system.
 The top program runs on a bank server and makes payments from an account,
 whilst the bottom one runs on an ATM and allows withdrawals.
 The flaws in this are numerous, but to spot them requires a knowledge of
 this language's 
\emph on
atomic transactions
\emph default
.
\end_layout

\begin_layout Standard
An atomic transaction is an instruction which cannot be divided into further
 instructions, hence it is 
\emph on
atomic
\emph default
 in the democratic sense, and it is a 
\emph on
transaction
\emph default
 since it will either be carried out or not, it cannot fail at a half-completed
 stage (since that would imply that the atomic instruction can be split
 into two).
 The implementation of high-level atomic transactions (such as atomic functions)
 is an area of parallel programming research, although is difficult to realise
 due to the Two Generals problem
\begin_inset CommandInset citation
LatexCommand cite
key "L.Lamport1982"

\end_inset

.
 Atomic transactions are thus usually very low level and reflect the architectur
e of the machine.
 The reason this becomes problematic is that atomic transactions are often
 at a much lower level than the source language of the system, making them
 invisible to someone without knowledge of the compiler.
\end_layout

\begin_layout Standard
In this example, the most damning flaws are the balance modifications which
 suffer from 
\emph on
race conditions
\emph default
 (non-deterministic output depending on how the threads are interleaved,
 which is undefined).
 The reassignment of the balance by the ATM looks straighforward: the new
 balance is the old balance minus the amount withdrawn.
 However, that is certainly not what this line of code actually means to
 the machine.
 This becomes clearer when we see it in terms of the equivalent atomic transacti
ons, which look something like Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:A-deconstruction-of"

\end_inset

.
\end_layout

\begin_layout Standard
All values must be loaded into registers inside the CPU before they can
 be processed, but by copying the values in this way we destroy their meaning
 within our program.
 
\family typewriter
balance
\family default
 is data stored in a memory location; the copy in the register is not stored
 at that location, thus the value of 
\family typewriter
registerA
\family default
 is not the account balance.
 It is a number which happened to equal the account balance 
\emph on
at the time it was loaded
\emph default
, but we can assume nothing more about it.
 It is perfectly acceptable for the server to modify the balance (the value
 stored at the defined location in memory) half-way through an ATM withdrawal,
 since that's the whole point of parallel, concurrent execution; yet that
 modification will be lost when the ATM finishes the withdrawal, as the
 new contents of 
\family typewriter
registerA
\family default
 will overwrite whatever changes have been made.
 Thus a possible execution of these threads may look like the following:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="9" columns="5">
<features>
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
t
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Instruction
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Balance
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ATM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Server
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ATM loads balance
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Server sends £200 payment
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ATM deducts £10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Server loads balance
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Server deducts £200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£500
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Server stores its value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ATM stores its value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£300
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ATM gives out a £10 note
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£490
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
£300
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
In this scenario there has been £210 taken out of the account, but only
 £10 has been deducted from the balance.
 For the computer this is perfectly valid code, however 
\emph on
our assumptions about what it proves
\emph default
 are severely at fault: the system modelled by the program's algebra is
 not isomorphic to a banking system, but we thought it was.
\end_layout

\begin_layout Standard
This example shows how dangerous it can be to make assumptions in a parallel
 environment; how seemingly simple constructs such as 
\family typewriter
x++
\family default
 actually decompose into multiple statements, any of which can be preempted
 (and invalidated) by another thread; and why parallel programming with
 mutable, shared memory is a hard problem with hidden pitfalls.
\end_layout

\begin_layout Standard
This is of course not the only way to program in parallel.
 Other approaches include:
\end_layout

\begin_layout Itemize
Software Transactional Memory, which abstracts memory accesses through a
 software library to facilitate high-level transactions.
\end_layout

\begin_layout Itemize
Actor models, which extend the Object Oriented paradigm of message passing
 to make each object a standalone Actor, which all run in parallel.
\end_layout

\begin_layout Itemize
Dataflow languages, where computations are built as networks of operations
 through which data is passed.
\end_layout

\begin_layout Itemize
Concurrent Functional Programming, which exploits pure functional programming's
 lack of mutability and execution order to distribute programs without the
 need for synchronisation.
\end_layout

\begin_layout Itemize
Futures (or Promises), where values can be used in calculations even if
 they haven't been worked out yet.
\end_layout

\begin_layout Standard
The model adopted by CUDA is threaded, so none of the above systems can
 help us write correct concurrent programs.
 In fact many uses of CUDA are similar in principle to a dataflow language,
 but if this is desired then it must still be enforced manually on top of
 the threaded interface.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{A simple bank server which provides monthly services:}
\end_layout

\begin_layout Plain Layout


\backslash
WHILE |keepRunning| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

 
\backslash
COMMENT{See if this month's payments have been made}
\end_layout

\begin_layout Plain Layout

 
\backslash
IF |lastPayments| < |thisMonth|
\end_layout

\begin_layout Plain Layout

  |balance| := |balance| 
\backslash
times (1+|rate|) 
\backslash
rcomment{Add on interest}
\end_layout

\begin_layout Plain Layout

  
\backslash
FOR |order | in | standingOrders| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

   |pay|(|order|.|recipient|,|order|.|amount|)
\end_layout

\begin_layout Plain Layout

   |balance| := |balance|-|order|.|amount|
\end_layout

\begin_layout Plain Layout

  |lastPayments|++
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{A complementary program for an ATM:}
\end_layout

\begin_layout Plain Layout


\backslash
WHILE |keepRunning| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

 
\backslash
IF |pin| = |accountPin| 
\backslash
land |action| = |withdraw|
\end_layout

\begin_layout Plain Layout

  |balance| := |balance| - |amount|
\end_layout

\begin_layout Plain Layout

  |give|(|amount|)
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:A-subtley-flawed"

\end_inset

A subtley flawed banking system, with simple algorithms for the server and
 ATM 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{Atomic instructions in pseudo-x86 machine language}
\end_layout

\begin_layout Plain Layout

|loadValue|(|balance|,|registerA|)
\end_layout

\begin_layout Plain Layout

|loadValue|(|amount|,|registerB|)
\end_layout

\begin_layout Plain Layout

|subtract|(|registerA|,|registerB|)
\end_layout

\begin_layout Plain Layout

|storeValue|(|balance|,|registerA|)
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:A-deconstruction-of"

\end_inset

A deconstruction of the ATM's balance update line.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
The CUDA Model
\end_layout

\begin_layout Standard
Since this project focuses specifically on the use of Nvidia's CUDA (Compute
 Unified Device Architecture) interface, a more specific description of
 its operation and use from C is given here.
 There are many conflicting constraints which must be juggled to obtain
 the highest throughput, however we will follow Hoare's Dictum 
\begin_inset Quotes eld
\end_inset

Premature optimization is the root of all evil.
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Knuth1974"

\end_inset

 and only concern ourselves with those large-scale optimisations relevant
 for the implementation.
\end_layout

\begin_layout Subsection
Memory Hierarchy
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename grid-block-memory.gif
	height 40theight%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:CUDA-memory-hierarchy."

\end_inset

CUDA memory hierarchy.
 The Grid represents the GPU and each Block represents a multiprocessor
 (see section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Code-Hierarchy"

\end_inset

).
 From 
\begin_inset CommandInset citation
LatexCommand cite
key "Kanter2008"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
CUDA is an interface to Nvidia graphics cards, a topological overview of
 which can be seen in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:CUDA-memory-hierarchy."

\end_inset

.
 The components are structured in a hierarchy based around memory access:
 The graphics card's RAM (
\emph on
global memory
\emph default
) is the root of the tree, globally accessible but relatively slow (400-600
 clock cycles per access).
 Below this is the 
\emph on
shared memory
\emph default
 of the multiprocessors.
 This memory is accessible to every core in its multiprocessor, and this
 ultimately determines the coarse-grain structure of the algorithms used.
 Finally each core in a multiprocessor (there are 8) has its own 
\emph on
registers
\emph default
, directly read from and written to by the Arithmetic Logic Units (the mathemati
cal circuitry) of each core.
 We will neglect local memory, since it is as slow as global memory and
 its usage is seen as a bad idea (although to spot this requires trawling
 through object code).
 Texture memory is only useful for integrating rendering in a program, and
 we don't have enough constants to make use of constant memory.
\end_layout

\begin_layout Standard
Although important to keep in mind, registers will not be explicitly used
 in the project as the access times are comparable to those for shared memory
 (as long as concurrent reads access different 
\begin_inset Quotes eld
\end_inset

banks
\begin_inset Quotes erd
\end_inset

, an optimisation which we will not be concerned with here).
 In contrast, the difference in lookup time between shared memory (4 clock
 cycles) and global memory (up to 600 clock cycles) is significant
\begin_inset CommandInset citation
LatexCommand cite
key "Farber2008"

\end_inset

, so this should be the main performance concern at the algorithm design
 stage.
 
\emph on
Host memory
\emph default
, ie.
 the motherboard's RAM, is so slow that it should not be considered an option
 for storage during computations.
 In fact, the usual bottleneck for CUDA programs is the bandwidth of copying
 data between CPU and GPU.
 Thus for any performance gains to be made, all computation should take
 place solely on the GPU, with the results transferred back at the end.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Code-Hierarchy"

\end_inset

Code Hierarchy
\end_layout

\begin_layout Standard
CUDA separates CPU code from GPU code, and hides the graphics card from
 the host.
 Although it is not directly accessible to C programs in the way that RAM
 and registers are accessible, CUDA does provide functions to handle the
 device.
 For example a call to 
\family typewriter
cudaMemcpy(void* destination, void* source, int size, cudaMemcpyHostToDevice)
\family default
 will transfer 
\family typewriter
size
\family default
 dereferenced values from the pointer 
\family typewriter
source
\family default
 to the pointer 
\family typewriter
destination
\family default
.
 In this case the flag 
\family typewriter
cudaMemcpyHostToDevice
\family default
 is passed, indicating that 
\family typewriter
source
\family default
 points to a location in the host's memory whilst 
\family typewriter
destination
\family default
 points to a location in the GPU's global memory.
 The set-up and tear-down for a calculation is completely accomplished through
 the use of these functions, and is necessarily performed from host-side
 in (mostly) serial C.
 Ideally no other work should be done by the host, but this may be difficult
 in practice.
\end_layout

\begin_layout Standard
Code destined for the GPU is written in regular C with a few deviations.
 Firstly there can be no recursion, which unfortunately makes CUDA an unsuitable
 target for many elegant recursive algorithms.
 Secondly there can be no function pointers; this doesn't present too much
 of a problem for small projects with known inputs.
 More specific idiosyncracies will be covered where appropriate.
\end_layout

\begin_layout Standard
To facilitate the massive parallelism, CUDA code is designated as one of
 three distinct kinds of function: 
\emph on
host functions
\emph default
 (regular C functions running on the host), 
\emph on
device functions
\emph default
 (which run on the GPU and can only be called from there) and 
\emph on
kernel functions
\emph default
 (which run on the GPU but are invoked by the host).
 Host functions are specified in the usual way, whilst device and kernel
 functions have their signatures augmented with the keywords 
\family typewriter
__device__
\family default
 and 
\family typewriter
__global__
\family default
 respectively.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Definition-of-four"

\end_inset

 we see a simple CUDA program with prototypes for a host function 
\family typewriter
main
\family default
 (our entry point), a kernel function 
\family typewriter
foo
\family default
 and two device functions 
\family typewriter
bar
\family default
 and 
\family typewriter
baz
\family default
.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Function-hierarchy:-host"

\end_inset

 shows which functions can call each other.
 Note that since recursion is not allowed for device or kernel functions,
 any dependency between 
\family typewriter
bar
\family default
 and 
\family typewriter
baz
\family default
 must be mutually exclusive.
 To initiate computation on the GPU requires calling a kernel function from
 some host code, which uses its own syntax of the form
\begin_inset Newline newline
\end_inset


\family typewriter
 
\lang british
functionName<<<dimGrid,dimBlock>>>(arguments);
\lang english
 
\family default
where 
\family typewriter
arguments
\family default
 is a normal comma-separated list of arguments for the function, whilst
 
\family typewriter
dimGrid
\family default
 and 
\family typewriter
dimBlock
\family default
 are explained in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Thread-Hierarchy"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=C}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[frame=single]
\end_layout

\begin_layout Plain Layout

__device__ int bar(int arg1);
\end_layout

\begin_layout Plain Layout

__device__ int baz(int arg1);
\end_layout

\begin_layout Plain Layout

__global__ void foo(int arg1);
\end_layout

\begin_layout Plain Layout

int main();
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Definition-of-four"

\end_inset

Declaration of four CUDA functions: main is a host function, foo is a kernel
 function whilst bar and baz are device functions.
 Returns and arguments are arbitrary, except that kernel functions must
 return void.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename device_kernel_host_reachability.png
	height 25theight%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Function-hierarchy:-host"

\end_inset

Function hierarchy: host code can call kernel functions, kernel functions
 can call device functions and device functions can call each other (non-recursi
vely)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Thread Hierarchy
\begin_inset CommandInset label
LatexCommand label
name "sub:Thread-Hierarchy"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename execution-model.gif
	height 45theight%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:CUDA-thread-hierarchy."

\end_inset

CUDA thread hierarchy.
 From 
\begin_inset CommandInset citation
LatexCommand cite
key "Kanter2008"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
CUDA has several layers of organisation for threads, shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:CUDA-thread-hierarchy."

\end_inset

.
 Each 
\emph on
thread
\emph default
 is part of a 
\emph on
thread block
\emph default
, and each thread block is part of a 
\emph on
grid
\emph default
.
 The grid and its blocks each have 
\emph on
dimensions
\emph default
, similar to an array; purportedly for convienience reasons, but actually
 a necessity due to CUDA's in-built limitations
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Initial attempts at implementing this project tried to avoid blocks and
 grids, instead opting for a simple array (a single one-dimensional block
 in a zero-dimensional grid) of threads.
 However this had to be abandoned since such arrays can only be 512 threads
 long.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
The idea of block dimensions is to give each thread a location in a space.
 For a one-dimensional block, each thread can get its location via the name
 
\family typewriter
threadIdx.x
\family default
.
 In a two-dimensional block there is a non-unique 
\family typewriter
threadIdx.x
\family default
 specifying the 'column' and a non-unique 
\family typewriter
threadIdx.y
\family default
 specifying the 'row'.
 These can be combined to give a unique ID for the thread if the size of
 the block is known, which can be accessed as 
\family typewriter
blockDim.x
\family default
 and 
\family typewriter
blockDim.y
\family default
.
 Thus 
\family typewriter
threadIdx.x 
\begin_inset Formula $+$
\end_inset

 (blockDim.x 
\begin_inset Formula $\times$
\end_inset

 threadIdx.y)
\family default
 is unique to each thread.
 Similarly in three dimensions there is a 
\family typewriter
threadIdx.z
\family default
 and a 
\family typewriter
blockDim.z
\family default
 which can give a unique ID via 
\family typewriter
threadIdx.x 
\begin_inset Formula $+$
\end_inset

 blockDim.x 
\begin_inset Formula $\times$
\end_inset

 (threadIdx.y 
\begin_inset Formula $+$
\end_inset

 blockDim.y 
\begin_inset Formula $\times$
\end_inset

 threadIdx.z)
\family default
.
 Note that these values are always defined, but are set to 1 if not used
 (for example in a one dimensional block 
\family typewriter
threadIdx.y
\family default
, 
\family typewriter
threadIdx.z
\family default
, 
\family typewriter
blockDim.y
\family default
 and 
\family typewriter
blockDim.z
\family default
 are all 1).
 The same is true for a grid of blocks, except it can only be one or two
 dimensional 
\begin_inset CommandInset citation
LatexCommand cite
key "Nvidia2009"

\end_inset

.
 The equivalent bindings are 
\family typewriter
gridDim.x
\family default
, 
\family typewriter
gridDim.y
\family default
, 
\family typewriter
blockIdx.x
\family default
 and 
\family typewriter
blockIdx.y
\family default
.
 There are no grid index (
\family typewriter
Idx
\family default
) bindings since there is only ever one grid.
\end_layout

\begin_layout Standard
The unique IDs defined in this way are very useful for distributing a workload,
 as they allow unique indexing of an array.
 For example, consider the simple kernel function in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simple-CUDA-kernel"

\end_inset

 for summing two vectors.
 It calculates the vector 
\begin_inset Formula $C$
\end_inset

 from the relationship 
\begin_inset Formula $A_{i}+B_{i}=C_{i}$
\end_inset

, using the mapping 
\begin_inset Formula $i\equiv$
\end_inset


\family typewriter
threadIdx.x 
\family default
to ensure that every element is calculated exactly once.
 When invoked by a host function with a call such as
\family typewriter
 
\lang british
foo<<<1,N>>>(A,B,C);
\family default
\lang english
, each element of 
\begin_inset Formula $C$
\end_inset

 will be calculated in its own thread (with N threads in total, requiring
 at least N elements following the pointers).
\end_layout

\begin_layout Standard
This usage of CUDA is typical, and allows a stream processing/dataflow style
 within the threaded model.
 Moreover, allowing threads to obtain unique indices prevents conflicts,
 since there is a simple way to ensure threads are accessing different areas
 of memory and thus not overwriting each other.
\end_layout

\begin_layout Standard
To specify the dimensions of the blocks and grid, the extended syntax for
 the kernel function invocation is used.
 The first argument in the triple angle brackets gives the grid dimensions
 and the second gives the block dimensions.
 These have the type 
\family typewriter
dim3
\family default
 (part of the CUDA libraries) and unspecified dimensions default to 1.
 Thus a single integer specifies a one-dimensional structure, whilst a call
 such as 
\family typewriter
dim3(x,y)
\family default
 specifies a two dimensional 
\begin_inset Formula $x\times y\times1$
\end_inset

 structure and 
\family typewriter
dim3(x,y,z)
\family default
 gives a three dimensional 
\begin_inset Formula $x\times y\times z$
\end_inset

 structure.
 These can be used within the triple arrows and implicitly contain the number
 of threads to run.
 Two more optional arguments won't be covered here as they have very specific
 uses (externally defined shared memory and data streams).
\end_layout

\begin_layout Standard
It is important to be aware of the limits imposed on blocks and grids (especiall
y since no bound checking is performed and no errors are given): block dimension
s are limited to 
\begin_inset Formula $512\times512\times64$
\end_inset

 threads and each block can contain at most 512 threads (ie.
 
\begin_inset Formula $x\times y\times z\leq512$
\end_inset

).
 The dimensions of a grid are limited to 
\begin_inset Formula $65535\times65535\times1$
\end_inset

, with no mention other than this of an explicit limit on the number of
 blocks in a grid (although only 8 can run at once on each multiprocessor,
 but CUDA manages this).
\end_layout

\begin_layout Standard
A final consideration to be aware of is that the shared memory in a block
 is accessed in a perculiar way: firstly, if a kernel function allocates
 an array in shared memory then only one array gets created, even if 512
 running threads pass the line which does the allocation.
 Secondly there can only ever be one array in shared memory: if you want
 more than one then they will have to be concatenated together, and the
 types cast appropriately for every access.
 Thirdly the size of the array must be a raw number (using a preprocessor
 macro to write this is fine); there is no way to specify a shared memory
 array without compiling in the length.
 These requirements deserve special attention since the shared memory of
 a block/multiprocessor should be the main hub of activity in a suitably
 parallel algorithm.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=C}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[frame=single]
\end_layout

\begin_layout Plain Layout

__global__ void foo(float* A, float* B, float* C) {
\end_layout

\begin_layout Plain Layout

  C[threadIdx.x] = A[threadIdx.x] + B[threadIdx.x];
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Simple-CUDA-kernel"

\end_inset

Simple CUDA kernel function to add two vectors in parallel.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Smoothed-Particle Hydrodynamics
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{Serial SPH algorithm}
\end_layout

\begin_layout Plain Layout


\backslash
FOR |particle1 | in | particles| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

 
\backslash
FOR |particle2 | in | particles| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

  
\backslash
IF |particle1| 
\backslash
neq |particle2|
\end_layout

\begin_layout Plain Layout

   |interact|(|particle1|, |particle2|)
\end_layout

\begin_layout Plain Layout

  
\backslash
FI
\end_layout

\begin_layout Plain Layout

 
\backslash
OD
\end_layout

\begin_layout Plain Layout


\backslash
OD
\end_layout

\begin_layout Plain Layout


\backslash
FOR |particle | in | particles| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

 |update|(|particle|)
\end_layout

\begin_layout Plain Layout


\backslash
OD
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:Naive-serial-implementation"

\end_inset

Naive serial implementation of Smoothed-Particle Hydrodynamics
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{Parallel SPH algorithm for NxN threads with sequential IDs}
\end_layout

\begin_layout Plain Layout

|i| := |ID| 
\backslash
% N
\end_layout

\begin_layout Plain Layout

|j| := (|ID| - |i|) / N
\end_layout

\begin_layout Plain Layout

|interact|(|particles|[|i|], |particles|[|j|])
\end_layout

\begin_layout Plain Layout

|__syncthreads|() 
\backslash
rcomment{waits for all threads to catch up}
\end_layout

\begin_layout Plain Layout


\backslash
IF |i| = 0
\end_layout

\begin_layout Plain Layout

 |update|(|particles|[|j|])
\end_layout

\begin_layout Plain Layout


\backslash
FI
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:Naive-parallel-implementation"

\end_inset

Naive parallel implementation of Smoothed-Particle Hydrodynamics
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Physical model being simulated in this project is a 
\emph on
Smoothed-Particle Hydrodynamics
\emph default
 (SPH) system.
 In this model, the behaviour of a large number of atoms and molecules in
 a fluid is approximated with a much smaller number of 
\emph on
particles
\emph default
 with a much larger spatial extent.
 These particles carry various bulk properties in their representation of
 the fluid, which are mutated over time.
 For this computational problem we will only concern ourselves with the
 spatial properties: the coordinates and the characteristic size, known
 as the 
\emph on
smoothing length
\emph default
, of each particle.
 In a perfect SPH model, the interactions between every particle with every
 other particle are calculated, the properties are then updated based on
 the results, then the process is repeated.
 This models the time-evolution of the system by approximating a time integral
 with steps.
\end_layout

\begin_layout Standard
To process these interactions requires 
\begin_inset Formula $O\left(N_{particles}^{2}\right)$
\end_inset

 operations, whilst to update the properties requires 
\begin_inset Formula $O\left(N_{particles}\right)$
\end_inset

.
 For a serial algorithm, such as the loop shown in algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Naive-serial-implementation"

\end_inset

, these translate directly into time.
 However, there is no dependency between the calculations inside a step,
 making this an embarassingly parallel problem.
 Thus a parallel algorithm could work them all out at once using 
\begin_inset Formula $N_{particles}^{2}$
\end_inset

 processors and do the same job in constant time, as seen in algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Naive-parallel-implementation"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename particle_functions.png
	width 70col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Gaussian-kernel-functions"

\end_inset

Gaussian kernel functions for particles in a one-dimensional Smoothed-Particle
 Hydrodynamics system.
 Every particle interacts with every other particle, but after a distance
 the contributions become negligible.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
This is still incredibly wasteful, and we can trim down the calculations
 to perform considerably fewer comparisons by exploiting the nature of the
 model.
 In SPH each particle has a 
\begin_inset Quotes eld
\end_inset

shape
\begin_inset Quotes erd
\end_inset

 defined by a 
\emph on
kernel function
\emph default
 (not to be confused with the concept of a kernel function in CUDA!), which
 governs the amplitude of particle interactions, as shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Gaussian-kernel-functions"

\end_inset

.
 Typical functions are Gaussians and cubic splines, but can be anything
 which falls off over distance.
 The rate of fall off is governed by the smoothing length, but in the case
 of something like a Gaussian it never quite reaches zero.
 Hence every particle 
\emph on
should
\emph default
 interact with all of the others, but the individual contributions become
 negligible after a long enough distance.
 A safe approximation, therefore, is to limit the interactions to those
 particles falling within this distance of each other, the 
\emph on
nearest neighbours
\emph default
.
 This brings down the number of computations to perform, however the number
 of nearest neighbours depends on the density and is thus still a linear
 function of 
\begin_inset Formula $N_{particles}$
\end_inset

, keeping our order of magnitude at 
\begin_inset Formula $O\left(N_{particles}^{2}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Another insightful fact about SPH is that we can derive more accurate results
 if the smoothing length becomes a function of the local density, with the
 length contracting for more densely packed spaces.
 This allows us to more efficiently concentrate out simulation efforts,
 as we can waste as few particles as possible in boring, sparsely populated
 regions, and in return we get a higher resolution for the areas containing
 more interactions.
 This refinement, as well as bringing efficiency in particle rationing,
 also brings down the number of nearest neighbours.
 In fact, by making the smoothing length decrease with 
\begin_inset Formula $N_{particles}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{eqnarray*}
N_{nearestneighbours}\left(N_{particles}\right) & \propto & \underset{\text{{density}}}{\underbrace{\frac{N_{particles}}{V_{space}}}}\times\underset{\text{(normalised) volume of interaction}}{\underbrace{\frac{L_{smoothing}\left(N_{particles}\right)^{3}}{V_{space}}}}\\
 & \propto & N_{particles}\times L_{smoothing}\left(N_{particles}\right)^{3}\\
 & \propto & N_{particles}\times V_{nearestneighbours}\left(N_{particles}\right)\\
 & \propto & N_{particles}\times\frac{1}{N_{particles}}\\
 & \propto & 1\end{eqnarray*}

\end_inset

Hence the number of neighbours is on the order of constant, making each
 particle's interactions 
\begin_inset Formula $O\left(1\right)$
\end_inset

 and thus the whole system's interactions 
\begin_inset Formula $O\left(N_{particles}\right)$
\end_inset

.
 This saves us a factor of 
\begin_inset Formula $N_{particles}$
\end_inset

 calculations by restricting ourselves to the nearest neighbours, which
 are the only non-negligible contributions.
\end_layout

\begin_layout Standard
Whilst this speedup seems simple, in fact it is deceptive.
 In order to work out which particles are nearest neighbours, we need to
 compare their positions.
 To find all of the nearest neighbours of a particle is thus an 
\begin_inset Formula $O\left(N_{particles}\right)$
\end_inset

 operation, and to find all of the nearest neighbours for the system is
 
\begin_inset Formula $O\left(N_{particles}^{2}\right)$
\end_inset

 and we are back to where we started.
 However there are algorithms to help us find these neighbours with fewer
 comparisons, which this project implements.
\end_layout

\begin_layout Subsection
The Gridding Algorithm
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename sph_grid.png
	width 45col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A two-dimensional SPH system.
 Blue dots are particle positions and the radii of the red circles are equal
 to the distance beyond which interactions are deemed negligible.
 The introduction of a grid with said distance as its cell size captures
 all meaningful interactions within a particle's cell or those adjacent
 & diagonal.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
It would seem useful to keep track of each particle's nearest neighbours
 once they've been identified, but this would not help us since the particles
 move between time steps, which changes their neighbours from step to step.
 One method of tracking particles that isn't invalidated at each step is
 to construct a grid and track each particle's grid cell.
 By choosing a grid size equal to the largest interaction radius in the
 system, we can ensure that a particle and its nearest neighbours are always
 either in the same grid cell or at most one cell apart.
 This narrows down our search for nearest neighbours considerably, since
 we can concentrate our efforts on those neighbouring cells.
 It is important to note that the efficiency of this method is reduced when
 the difference between the largest interaction radius and the average interacti
on radius becomes large (this is due to overcrowded cells, where most of
 the particles in neighbouring cells are not nearest neighbours and are
 thus wasted comparisons), in other words when the density is highly non-uniform.
\end_layout

\begin_layout Standard
It is also worth explicitly contrasting a grid of cells containing particles,
 decribed in this paragraph, and CUDA's grid of blocks containing threads,
 described previously.
 They have no relation in this implementation.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
An attempt was made to model the SPH grid directly with a CUDA grid, but
 the two-dimensional limitation of CUDA grids prevented this.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Implementation
\end_layout

\begin_layout Standard
There are many ways to implement the gridding algorithm for Smoothed-Particle
 Hydrodynamics.
 It was important to keep the solutions general, such that any datastructures
 and algorithms could be used to model the particles and interactions, so
 no assumptions could be made about either, except that the particles contain
 three-dimensional Cartesian coordinates and a size.
\end_layout

\begin_layout Standard
Four different approaches have been taken for this project, which will be
 referred to as the 
\emph on
linked list
\emph default
, 
\emph on
sentinel
\emph default
, 
\emph on
pair-array
\emph default
 and 
\emph on
padded
\emph default
 implementations.
 Other possibilities were investigated but ultimately abandoned, the reasons
 for this are explored in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Unworkable-Solutions"

\end_inset

.
 Full source code listings can be found in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Source-Code-Listings"

\end_inset

.
\end_layout

\begin_layout Subsection
Common Code
\end_layout

\begin_layout Standard
All implementations have code in common.
 For the sentinel, pair-array and padded implementations these are shared
 at the include level, whilst the linked lists implementation has slight
 incompatibilities which prevents its complete integration.
\end_layout

\begin_layout Standard
Aside from file reading (file_reading.c), which is trivial from a CSV spreadsheet
, the common code is kept in datatypes.c and common_functions.c.
 Functions specific to an implementation are in cuda_functions.cu, sentinel_funct
ions.c and pair_array_functions.c whilst the entry points for each are cuda_tests.c
u, sentinel_tests.c and pair_array_tests.c.
 An attempt was made to combine the front-ends but it proved difficult to
 include the CUDA parts due to GCC's rejection of the non-standard syntax
 (Nvidia supplies a modified compiler), so this was abandoned.
\end_layout

\begin_layout Standard
Common functionality is limited to high-level grid operations, such as getting
 the largest numbers of particles in a cell, or else nothing to do with
 the grid, such as numerical conveniences.
 This is because the particle pointer (array) in the grid behaves in different
 ways for each implementation.
\end_layout

\begin_layout Subsection
Linked Lists
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename linkedlist_grid.png
	width 80col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DiagramLinked"

\end_inset

Diagram of the grid datastructure in the linked lists implementation.
 Each cell points to one of its particles, and each particle points to another
 particle from the same cell, such that every particle has exactly one cell
 or particle pointing to it.
 Processing each particle in a cell means following the arrows until they
 stop.
 Construction of these lists is very simple, as is using them, but passing
 the data around is more complex than using a pointer (array).
 Empty cells point to null, and every particle contains a pointer to its
 cell (so that the start of its list can be reached).
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
A linked list is a simple data structure built from 
\emph on
nodes
\emph default
.
 Each node stores some data and a pointer to the next node in the list.
 This means that data can be spread throughout the memory, nodes can be
 added and removed from a linked list in constant time and the length is
 not fixed or bounded (except by available RAM).
 Linked lists are powerful, for example much of the functionality in the
 LISP and Scheme languages rely on recursive use of linked lists, but they
 do have some disadvantages.
 For example, getting the length of a linked list is 
\begin_inset Formula $O\left(N_{nodes}\right)$
\end_inset

 and, if it's a singly linked list, there is no way to go backwards through
 the nodes.
\end_layout

\begin_layout Standard
The Linked Lists grid implementation is a serial algorithm which has a branch
 for the grid and a branch for brute force.
 Inside the grid is an array of particles in arbitrary order and an array
 of 
\emph on
cells
\emph default
 in column-major order (go through every z before increasing y, go through
 every y before increasing x).
 Each cell is the first node of a linked list and, if it contains any particles,
 is followed by them in the chain of pointers, as shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DiagramLinked"

\end_inset

.
 The end is marked by a null pointer.
\end_layout

\begin_layout Standard
Processing particle interactions via the grid is achieved by following the
 particle's container pointer to reach the cell; walking the linked list
 from that cell; then visiting the nearest neighbour cells and walking their
 linked lists.
 To process interactions via brute force can be done simply by looping through
 the particles array.
 Unfortunately, despite many changes to facilitate it, this is not a suitable
 implementation for CUDA, since linked lists can be spread all over the
 RAM and thus are inefficient to transfer to multiprocessor shared memory,
 whilst an unsorted particle array cannot be loaded efficiently without
 searching it for relevant particles first.
\end_layout

\begin_layout Subsection
Sentinels
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename sentinels_grid.png
	width 80col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DiagramSentinel"

\end_inset

Diagram of the grid datastructure in the sentinels implementation.
 Each dark entry in the particles array is a dummy (with an ID of -1) which
 marks the start of a new cell, and thus the particles between two sentinels
 are from the same cell.
 Cells are stored in column-major order.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
A sentinel is a dummy value, used to represent the end of a datastructure.
 In this SPH implementation the sentinels mark the boundaries between cells,
 and are thus distributed through the particle array itself as shown in
 figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DiagramSentinel"

\end_inset

.
 No secondary datastructures like lists are involved, the particles are
 grouped by cell and there is a simple way to get all of the particles of
 a cell as an 
\begin_inset Quotes eld
\end_inset

array
\begin_inset Quotes erd
\end_inset

 (ie.
 just take a pointer, since they're grouped).
\end_layout

\begin_layout Standard
The problem with the sentinels approach is that many common operations become
 dependent on larger powers of 
\begin_inset Formula $N_{particles}$
\end_inset

.
 For example to look up a specific cell requires traversing the array and
 counting the sentinels on the way, which is 
\begin_inset Formula $O\left(N\right)$
\end_inset

.
 Also, whilst grouped into cells and sorted into grid-order, the particles
 are not in the best state to be loaded by CUDA.
 To efficiently copy data to shared memory with CUDA requires a thread for
 every element, the elements to be arranged contiguously in RAM and for
 the number to be known in advance.
 There is no way for a thread which just loaded a sentinel to tell those
 threads further on that they should stop, since they may have already finished
 loading particles from the wrong cell.
 These inefficiencies make this solution undesirable, but it was useful
 to implement as a simple testbed.
\end_layout

\begin_layout Subsection
Pair Arrays
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename pair_array_grid.png
	width 80col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DiagramPair"

\end_inset

Diagram of the grid datastructure in the 
\begin_inset Quotes eld
\end_inset

pair-array
\begin_inset Quotes erd
\end_inset

 implementation.
 The array of particles stores two distinct arrays: the first particles
 (dark) each represent a cell in column-major order, the rest are the actual
 particles grouped by cell and once again stored in column-major order.
 The 
\begin_inset Quotes eld
\end_inset

cells
\begin_inset Quotes erd
\end_inset

 in the first part of the array point to the start of their members in the
 second part.
 They store these indices as their particle ID, but negated so they cannot
 be confused with real particles (who's IDs go up from zero).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename /home/chris/Files/Work/Project/gridding-serial/Results/pair-array_setup.png
	width 100col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:The-overhead-from"

\end_inset

The overhead from setting up a grid follows a power law of 
\begin_inset Formula $1.03\approx1$
\end_inset

 in serial and 
\begin_inset Formula $0.99\approx1$
\end_inset

 in parallel, making this an 
\begin_inset Formula $O\left(N_{particles}\right)$
\end_inset

 operation.
 The lower data points are mainly constant overhead, bias the trend line
 and thus the most pronounced have been discarded during the fit.
 It is important to note that the CUDA initialisation is done with serial
 code on the host, and does all of the work of the serial code before constructi
ng padded arrays and sending them to the device and back, hence why the
 parallel points are always above the serial.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/chris/Files/Work/Project/gridding-serial/Results/pairs_grid-brute-force_times.png
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Performance-of-pair"

\end_inset

Comparison between 
\begin_inset Quotes eld
\end_inset

pair arrays
\begin_inset Quotes erd
\end_inset

 serial grid implementation (red), brute force serial implementation (green),
 
\begin_inset Quotes eld
\end_inset

padded
\begin_inset Quotes erd
\end_inset

 parallel grid implementation (blue) and brute force parallel implementation
 (purple).
 The power laws governing the scaling for each line as it tends to infinity
 are arranged anticlockwise from the bottom.
 The brute force methods have powers 
\begin_inset Formula $\sim2$
\end_inset

 and the grids have powers 
\begin_inset Formula $\sim1$
\end_inset

, where serial algorithms are slightly higher and parallel algorithms are
 slightly lower.
 The serial grid implementation reached the most particles without failure,
 although its speed became impractical to test any further.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Rather than keep dummies spread throughout the particle array, in this implement
ation they are coalesced into a complementary array, stored at the start
 of the particles array.
 Each dummy/sentinel contains (as the negation of it's ID) the index of
 the array where it's particles start.
\end_layout

\begin_layout Standard
This is much more efficient than the sentinel implementation, since cell
 lookups only require 2 dereferences (ie.
 constant time) and cell lengths can be found by subtracting the index stored
 in the current dummy with that in the next dummy.
 After the array of dummies, all of the particles are contiguous and grouped
 by cell, which is better for use by CUDA but still not perfect.
 A simple transformation can be used, however, to obtain the padded implementati
on of section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Padded"

\end_inset

.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Performance-of-pair"

\end_inset

 shows the power laws of the pair-array grid compared to brute force on
 the same data.
 The power of 1.05 is near-optimal in terms of scaling, clearly demonstrating
 the grid's performance advantage over comparing every particle.
 We can see the overhead caused by setting up the grid in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-overhead-from"

\end_inset

, which scales as 
\begin_inset Formula $N^{1.03}$
\end_inset

 which is, once again, near-optimal.
 This is the most sensible implementation to use in serial, and it is thus
 used to initialise the CUDA calculations.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Padded"

\end_inset

Padded
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename padded_grid.png
	width 80col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DiagramPadded"

\end_inset

Diagram of the grid datastructure in the 
\begin_inset Quotes eld
\end_inset

padded
\begin_inset Quotes erd
\end_inset

 implementation used by CUDA.
 Particles are stored in column-major order, with each cell taking up the
 same amount of room.
 Here there are three cells of seven particles, although the left two need
 some dummies to make sure they pad out to the right length.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The simplest implementation for CUDA is to group the particles by cell,
 then pad out each group until they are all the same length, as seen in
 figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DiagramPadded"

\end_inset

.
 This makes the implementation similar to the N-body simulation in 
\begin_inset CommandInset citation
LatexCommand cite
key "Prins"

\end_inset

, but with the complication of not knowing the required number of threads,
 etc.
 
\emph on
a priori
\emph default
.
 Padding in this way wastes memory, but allows every cell to be handled
 in an identical way, which makes life easier when spawning thousands of
 instances of the same code.
 Also, having contiguous groups lets the memory accesses be coalesced (the
 whole group can be transferred at once, this is handled automatically by
 CUDA), resulting in higher performance.
\begin_inset CommandInset citation
LatexCommand cite
key "Nvidia2009"

\end_inset


\end_layout

\begin_layout Standard
The difficulty with the padded approach is that the largest number of particles
 in a cell needs to be known before any memory allocation can take place.
 We get around this in two ways: firstly we reuse the pair-array implementation
 on the host, so that we can read in particles straight away without performing
 any padding.
 We then find the largest cell size and allocate based on that.
 The second branch for 
\begin_inset Quotes eld
\end_inset

handling
\begin_inset Quotes erd
\end_inset

 this has roots in CUDA's memory model: each thread block can only have
 one array in shared memory, which must be declared with a constant (ie.
 a raw number) size.
 A simple preprocessor macro lets us explicitly define this size, but since
 this happens at compile-time it is possible that the input data contains
 a cell larger than this compiled-in limit.
 In this case we simply print a warning and the calculation is aborted,
 which is not an elegant way to handle the scenario but allows us to keep
 clear of metaprogramming (which is often more trouble than it's worth).
\end_layout

\begin_layout Standard
The padded approach is parallel and shown in algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:CUDA-sph"

\end_inset

.
 This corresponds closely to the C code in appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Source-Code-Listings"

\end_inset

, except for the usual boilerplate to implement these high-level concepts.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{program}
\end_layout

\begin_layout Plain Layout


\backslash
mbox{Parallel SPH grid, to be run concurrently by one thread per particle}
\end_layout

\begin_layout Plain Layout

|localparticles| := |particle|[2*|cellsize|] 
\backslash
rcomment{define shared array}
\end_layout

\begin_layout Plain Layout

|localparticles|[|ID|
\backslash
%|cellsize|] = |allparticles|[|ID|]
\end_layout

\begin_layout Plain Layout


\backslash
FOR |n | in | neighbours| 
\backslash
DO
\end_layout

\begin_layout Plain Layout

 |localparticles|[|cellsize|+|ID| 
\backslash
% |cellsize|] = |n|[|ID|
\backslash
%|cellsize|]
\end_layout

\begin_layout Plain Layout

 |syncthreads|()
\end_layout

\begin_layout Plain Layout

 
\backslash
FOR |p | in | localparticles|[|cellsize|:] 
\backslash
DO
\end_layout

\begin_layout Plain Layout

  
\backslash
IF |p|=|localparticles|[|ID| 
\backslash
% |cellsize|]
\end_layout

\begin_layout Plain Layout

   
\backslash
rcomment{Do nothing}
\end_layout

\begin_layout Plain Layout

  
\backslash
ELSE
\end_layout

\begin_layout Plain Layout

   |interact|(|p|, |localparticles|[|ID| 
\backslash
% |cellsize|])
\end_layout

\begin_layout Plain Layout

  
\backslash
FI
\end_layout

\begin_layout Plain Layout

 
\backslash
OD
\end_layout

\begin_layout Plain Layout

 |syncthreads|()
\end_layout

\begin_layout Plain Layout


\backslash
OD
\end_layout

\begin_layout Plain Layout

|allparticles|[|ID|] = |localparticles|[|ID| 
\backslash
% |cellsize|]
\end_layout

\begin_layout Plain Layout


\backslash
end{program}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:CUDA-sph"

\end_inset

CUDA implementation of SPH grid
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "references"
options "plain"

\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
\begin_inset CommandInset label
LatexCommand label
name "sec:Unworkable-Solutions"

\end_inset

Unworkable Solutions
\end_layout

\begin_layout Standard
There were several approaches to the gridding algorithm considered but never
 implemented.
 These range from minor details to overarching conceptual shifts.
 A few are explored here to illustrate what is and is not a reasonable course
 to take when modelling parallel software in C and CUDA.
\end_layout

\begin_layout Subsection
Pure Pointer Arithmetic
\end_layout

\begin_layout Standard
In C the physical location of data is reified into data itself through the
 concept of 
\emph on
pointers
\emph default
, invoked by the address-of operator 
\family typewriter
&
\family default
.
 Pointers are pervasive in the C approach to programming, as they are the
 only way to achieve certain tasks (short of Godel numbering
\begin_inset CommandInset citation
LatexCommand cite
key "Goedel1931"

\end_inset

).
 A pointer is a positive (unsigned) integer which for an address in RAM
 that holds a certain piece of data.
 Pointers also have a 
\emph on
type
\emph default
 (in the loose, C sense of the term) which exists solely to provide a length.
 Upon 
\emph on
dereference
\emph default
, written 
\family typewriter
foo[index]
\family default
 where 
\family typewriter
foo
\family default
 is a pointer and 
\family typewriter
index
\family default
 an integer offset, an amount of data is fetched from RAM starting at the
 location
\family typewriter
 
\begin_inset Formula $\text{{foo}}+\left(\text{{sizeof}}\left(\text{{foo's}type}\right)\times\text{{index}}\right)$
\end_inset


\family default
 and of length 
\family typewriter
sizeof(foo's type)
\family default
.
 A shorthand for 
\family typewriter
foo[0]
\family default
 is 
\family typewriter
*foo
\family default
.
\end_layout

\begin_layout Standard
The direct manipulation of memory in this way allows an instantiation of
 the array datastructure, a random-access, fixed-size construct for storing
 a subset of the array's type.
 The exploitation of these abstracted structures and their underlying pointer
 implementation seemed immediately applicable to the problem of implementing
 the grid: namely, how to specify the contents of a cell with as little
 overhead as possible.
 For zero- and one-dimensional grids, the implementation using an array
 abstraction was obvious, along the lines of 
\family typewriter
[cell 0, cell 1, cell 2, ..., cell N]
\family default
, but the problem of unequal numbers of particles in each cell would cause
 either an extra dimension to be used, which although conceptually 
\begin_inset Quotes eld
\end_inset

close
\begin_inset Quotes erd
\end_inset

 would in fact use a non-contiguous area of memory, or the loss of constant-time
 lookups (caused by reading through the array).
 The use of pointer arithmetic on 
\begin_inset Quotes eld
\end_inset

arrays
\begin_inset Quotes erd
\end_inset

 (pointers) can solve this, by using a small collection of integers to refer
 to the various cell locations, and by incrementing and decrementing the
 pointers to expand and shrink the borders of the cells.
 In effect, the physical space of the grid can be implemented directly inside
 the RAM, such that the only operations necessary for the entire gridding
 algorithm are pointer increment and decrement.
\end_layout

\begin_layout Standard
Unfortunately the main advantage of this method is lost when higher dimensions
 are modelled, since contemporary RAM is one-dimensional which is insufficient
 to represent cell boundaries of two or more dimensions.
 Rather than achieving everything with fast 
\family typewriter
++
\family default
 and 
\family typewriter
--
\family default
 operators on the grid metadata, discontinuities would have to be taken
 into account when mutating cell contents in a higher dimension, and even
 worse it would be necessary to touch the particle data as it is shuffled
 from one cell (array) to another (since the arrays cannot shuffle around
 the particles in more than the x dimension).
\end_layout

\begin_layout Standard
This approach was therefore abandoned, despite the obvious simplicity and
 performance gains it would bring.
 However unsuitable as it was for this problem, it is certainly a worthy
 option to consider for one-dimensional models and machines with higher-dimensio
nal memory.
\end_layout

\begin_layout Subsection
Boundless Grids
\end_layout

\begin_layout Standard
A simplistic mapping of higher dimensions to one dimensional memory turns
 spaces into planes by tiling the slices, and turns planes into lines by
 concatenating the rows.
 An example used throughout this project looks like 
\family typewriter
[(0,0,0), (0,0,1), ..., (0,0,z_max), (0,1,0), (0,1,1), ..., (0,y_max,z_max), (1,0,0),
 (1,0,1), ..., (x_max,y_max,z_max)]
\family default
.
\end_layout

\begin_layout Standard
A problem inherent in this, however, is the requirement to bound the space.
 Simply by giving the coordinates a single unique address we have incorporated
 the artificial concepts of 
\begin_inset Quotes eld
\end_inset


\family typewriter
x_max
\family default

\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset


\family typewriter
y_max
\family default

\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset


\family typewriter
z_max
\family default

\begin_inset Quotes erd
\end_inset

 which have no grounding in reality or the Smoothed-Particle Hydrodynamics
 model.
 We have also completely neglected negative cell positions, as such addresses
 would not be unique and could not therefore be dereferenced or used as
 identifiers.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Negative particle positions are of course allowed in the four final implementati
ons, and are accounted for by giving the grid an offset from the particles;
 essentially locating the
\family typewriter
 (0,0,0)
\family default
 cell such that its position is less than those of every particle.
 The existence of these offsets makes explicit the fact that we've artificially
 truncated the lower bounds of the system.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
An attempt was made to overcome these limitations by using a space-filling
 method for addressing every coordinate in a countably infinite space.
 Rather than progressing solely in one dimension, reaching the 
\begin_inset Quotes eld
\end_inset

end
\begin_inset Quotes erd
\end_inset

 and then looping back to the 
\begin_inset Quotes eld
\end_inset

start
\begin_inset Quotes erd
\end_inset

, in this construction the array stores successive diagonal slices through
 the octants of the space, effectively enumerating the nodes of a space-filling
 tree.
 An example would be 
\family typewriter
[(0,0,0), (0,0,1), (0,1,0), (1,0,0), (0,0,2), (0,1,1), (0,2,0), (1,0,1),
 (1,1,0), (2,0,0), ...]
\family default
 which includes three diagonal slices through the positive octant, or equivalent
ly the first three layers of a space-filling tree with positive branches.
 Since the number of octants making up the whole of a space is finite (8)
 we can represent them all in a linear array by simply interleaving the
 elements.
\end_layout

\begin_layout Standard
This approach allows any cell coordinates to be addressed, thus there is
 no need to implement tricks like offsets to allow negative positions and
 the particles are free to move anywhere throughout the course of the simulation
 without the grid having to be modified.
 Storing an infinite number of cells in memory to facilitate this would
 not be possible, of course, but that doesn't mean that it's not a useful
 implementation for lazy (only when needed) evaluation.
\end_layout

\begin_layout Standard
Having such a general coordinate system would be a useful property for the
 grid, however given the constraints already imposed by CUDA such infinite
 data structures would be of little use; certainly not worth the added complexit
y in addressing for the small memory footprints it would see on an Nvidia
 GPU.
\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Source-Code-Listings"

\end_inset

Source Code Listings
\end_layout

\end_body
\end_document
